{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5312d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles inserted! Time taken: 4.63 seconds, Rows processed: 1000\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import configdbms\n",
    "\n",
    "conn = pymysql.connect(\n",
    "    host=configdbms.mysql[\"host\"],\n",
    "    port=configdbms.mysql[\"port\"],\n",
    "    user=configdbms.mysql[\"user\"],\n",
    "    passwd=configdbms.mysql[\"password\"],\n",
    "    db=configdbms.mysql[\"database\"],\n",
    "    autocommit=True\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS ia626_article_keywords;\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS ia626_keywords;\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS ia626_articles;\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE ia626_articles (\n",
    "    article_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    url TEXT,\n",
    "    title VARCHAR(255),\n",
    "    author VARCHAR(255),\n",
    "    date DATETIME NULL,\n",
    "    category VARCHAR(255),\n",
    "    article_body LONGTEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE ia626_keywords (\n",
    "    keyword_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    keyword VARCHAR(255) UNIQUE\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE ia626_article_keywords (\n",
    "    article_id INT,\n",
    "    keyword_id INT,\n",
    "    PRIMARY KEY (article_id, keyword_id),\n",
    "    FOREIGN KEY (article_id) REFERENCES ia626_articles(article_id),\n",
    "    FOREIGN KEY (keyword_id) REFERENCES ia626_keywords(keyword_id)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "date_formats = [\n",
    "    \"%Y-%m-%dT%H:%M:%S%z\",\n",
    "    \"%Y-%m-%dT%H:%M:%S\",\n",
    "    \"%a, %d %b %Y %H:%M:%S %z\",\n",
    "    \"%Y-%m-%d %H:%M:%S\",\n",
    "    \"%Y-%m-%d\"\n",
    "]\n",
    "\n",
    "blocksize = 20\n",
    "tokens = []\n",
    "insert_time = 0\n",
    "rows_processed = 0\n",
    "\n",
    "with open(\"foxnews_articless.csv\", \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        url, title, author, date_raw, category, article_body = row\n",
    "\n",
    "        dt_mysql = None\n",
    "        if date_raw:\n",
    "            for fmt in date_formats:\n",
    "                try:\n",
    "                    parsed = datetime.datetime.strptime(date_raw, fmt)\n",
    "                    dt_mysql = parsed.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    break\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        tokens.append((url, title, author, dt_mysql, category, article_body))\n",
    "\n",
    "        if len(tokens) >= blocksize:\n",
    "            start = time.time()\n",
    "            cursor.executemany(\n",
    "                \"\"\"\n",
    "                INSERT INTO ia626_articles (url, title, author, date, category, article_body)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                \"\"\",\n",
    "                tokens\n",
    "            )\n",
    "            insert_time += time.time() - start\n",
    "            tokens = []\n",
    "\n",
    "        rows_processed += 1\n",
    "if tokens:\n",
    "    start = time.time()\n",
    "    cursor.executemany(\n",
    "        \"\"\"\n",
    "        INSERT INTO ia626_articles (url, title, author, date, category, article_body)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        \"\"\",\n",
    "        tokens\n",
    "    )\n",
    "    insert_time += time.time() - start\n",
    "\n",
    "print(f\"Articles inserted! Time taken: {insert_time:.2f} seconds, Rows processed: {rows_processed}\")\n",
    "with open(\"semantic_tags.csv\", \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        article_id, tags_string = row\n",
    "\n",
    "        tags = [t.strip() for t in tags_string.split(\",\") if t.strip()]\n",
    "\n",
    "        for tag in tags:\n",
    "            cursor.execute(\n",
    "                \"INSERT IGNORE INTO ia626_keywords (keyword) VALUES (%s)\",\n",
    "                (tag,)\n",
    "            )\n",
    "\n",
    "            cursor.execute(\n",
    "                \"SELECT keyword_id FROM ia626_keywords WHERE keyword = %s\",\n",
    "                (tag,)\n",
    "            )\n",
    "            keyword_id = cursor.fetchone()[0]\n",
    "\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                INSERT IGNORE INTO ia626_article_keywords (article_id, keyword_id)\n",
    "                VALUES (%s, %s)\n",
    "                \"\"\",\n",
    "                (article_id, keyword_id)\n",
    "            )\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
